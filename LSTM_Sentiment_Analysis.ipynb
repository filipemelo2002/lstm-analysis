{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch import nn, optim\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")"
      ],
      "metadata": {
        "id": "nqU9jVOtHyVh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/twitter_training.csv'\n",
        "dataset = pd.read_csv(data_path, header=None)"
      ],
      "metadata": {
        "id": "0w1SaUqYGsen"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.hstack((dataset.iloc[0, 0:2].values,dataset.iloc[0, 3:].values, dataset.iloc[0, 2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcQpJ9Y3hCwH",
        "outputId": "be7d85bb-f51b-4496-9abe-cce11856bab2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([np.int64(2401), 'Borderlands',\n",
              "       'im getting on borderlands and i will murder you all ,',\n",
              "       'Positive'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.iloc[:, 2].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3dKWgVISf6-",
        "outputId": "9c979003-d2db-42b4-8761-b005f86c7aea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Positive', 'Neutral', 'Negative', 'Irrelevant'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "\n",
        "encoded_df = encoder.fit_transform(dataset.iloc[: , 2])\n",
        "\n",
        "dataset[2] = encoded_df\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "77HdXHl-WjR5",
        "outputId": "c83cc776-9cf1-4e9e-9c69-b21eaff82c81"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0            1  2                                                  3\n",
              "0  2401  Borderlands  3  im getting on borderlands and i will murder yo...\n",
              "1  2401  Borderlands  3  I am coming to the borders and I will kill you...\n",
              "2  2401  Borderlands  3  im getting on borderlands and i will kill you ...\n",
              "3  2401  Borderlands  3  im coming on borderlands and i will murder you...\n",
              "4  2401  Borderlands  3  im getting on borderlands 2 and i will murder ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fedfb5d6-91ac-44ae-955d-26654bcb6bae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>3</td>\n",
              "      <td>im getting on borderlands and i will murder yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>3</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>3</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>3</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>3</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fedfb5d6-91ac-44ae-955d-26654bcb6bae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fedfb5d6-91ac-44ae-955d-26654bcb6bae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fedfb5d6-91ac-44ae-955d-26654bcb6bae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0ac9f567-3be9-426e-ab94-f4af20788d90\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ac9f567-3be9-426e-ab94-f4af20788d90')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0ac9f567-3be9-426e-ab94-f4af20788d90 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 74682,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3740,\n        \"min\": 1,\n        \"max\": 13200,\n        \"num_unique_values\": 12447,\n        \"samples\": [\n          1616,\n          2660,\n          2335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Cyberpunk2077\",\n          \"Microsoft\",\n          \"TomClancysRainbowSix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 69491,\n        \"samples\": [\n          \"Thanks to @ Kain0025 for the raid. Thanks to @ gamingstreams and @ velonese002 for the bitts! And thanks to @ ColTrysTohete for hanging out and hanging out!. I hope to continue streaming regularly.. watch the w / @ Cohtstreams _ coming live!\",\n          \"How not to get bored about every damn thing in life.\",\n          \"The Best Way to Protect the Samsung Galaxy Note10+ buff.ly/2zkjIhU <unk> ^\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.iloc[0, 3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "awhpnHv2kONC",
        "outputId": "249112c2-bb0d-4c83-c3a6-08d7d742f911"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'im getting on borderlands and i will murder you all ,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "np.array(tokenizer.encode(dataset.iloc[0, 3:].to_string()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4_Ita7jrx-I",
        "outputId": "0f302ee8-72b1-4d94-e04c-675f18b89d86"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   18,   220,   220,   220,   545,  1972,   319,  4865,  4447,\n",
              "         290,  1312,   481,  5123, 27406,   986])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text =  re.sub(r'[^a-z\\s]', '', text)\n",
        "  text = re.sub(r'\\s+', ' ', text).strip()\n",
        "  return text"
      ],
      "metadata": {
        "id": "VyMkK-5ol6Eq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WordDataset(Dataset):\n",
        "  def __init__(self, path, max_length, tokenizer):\n",
        "      self.dataset = pd.read_csv(path, header=None)\n",
        "      self.dataset = self.dataset.dropna(subset=[2,3])\n",
        "      self.max_length = max_length\n",
        "      self.tokenizer = tokenizer\n",
        "      self.encoder = LabelEncoder()\n",
        "      encoded_df = self.encoder.fit_transform(self.dataset.iloc[: , 2])\n",
        "      self.dataset[3] = self.dataset[3].apply(clean_text)\n",
        "      self.dataset[2] = encoded_df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    text = self.dataset.iloc[index, 3]\n",
        "    label = self.dataset.iloc[index, 2]\n",
        "    encoded_token = self.tokenizer.encode(text)\n",
        "    if len(encoded_token) < self.max_length:\n",
        "        encoded_token = encoded_token + [0] * (self.max_length - len(encoded_token))\n",
        "    else:\n",
        "        encoded_token = encoded_token[:self.max_length]\n",
        "\n",
        "    return torch.tensor(encoded_token), torch.tensor(label, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "kwYuzGQ4JM0s"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_word_dataloader(\n",
        "    path = data_path,\n",
        "    batch_size = 4,\n",
        "    shuffle = False,\n",
        "    num_workers = 0,\n",
        "):\n",
        "\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = WordDataset(path, max_length=128, tokenizer=tokenizer)\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size = batch_size,\n",
        "      shuffle = shuffle,\n",
        "      num_workers = num_workers,\n",
        "  )\n",
        "\n",
        "  return dataloader, dataset"
      ],
      "metadata": {
        "id": "tYPhGA8kKjsr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader, dataset = create_word_dataloader()\n",
        "\n",
        "label = next(iter(data_loader))\n",
        "\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgTZ_biHMQeS",
        "outputId": "db2140e3-371a-4243-cbcc-f7c7898bc389"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  320,  1972,   319,  4865,  4447,   290,  1312,   481,  5123,   345,\n",
            "           477,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [   72,   716,  2406,   284,   262, 11637,   290,  1312,   481,  1494,\n",
            "           345,   477,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  320,  1972,   319,  4865,  4447,   290,  1312,   481,  1494,   345,\n",
            "           477,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  320,  2406,   319,  4865,  4447,   290,  1312,   481,  5123,   345,\n",
            "           477,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]]), tensor([3, 3, 3, 3])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim=4, num_layers=2, dropout = 0.3):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    pretrained_embedding_weights = torch.randn((vocab_size, embedding_dim))\n",
        "    self.embedding.weight.data.copy_(pretrained_embedding_weights)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.output_layer = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "  def forward(self, X):\n",
        "    hidden_states = torch.zeros(self.num_layers * 2, X.size(0), self.hidden_dim)\n",
        "    cell_states = torch.zeros(self.num_layers * 2, X.size(0), self.hidden_dim)\n",
        "    embedded = self.embedding(X)\n",
        "\n",
        "    _, (hidden, _) = self.lstm(embedded, (hidden_states, cell_states))\n",
        "    hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "    output = self.dropout(hidden)\n",
        "    return self.output_layer(output)\n"
      ],
      "metadata": {
        "id": "XgzCP__X4Fw2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_dim = 128\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-3\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "vocab_size = tokenizer.n_vocab\n",
        "\n",
        "\n",
        "model = SentimentLSTM(vocab_size, hidden_dim, embedding_dim)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-q6aDaU8o2b",
        "outputId": "189aaa35-b2fa-498d-8352-c3d4feeebc03"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentLSTM(\n",
              "  (embedding): Embedding(50257, 128)\n",
              "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (output_layer): Linear(in_features=256, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataloader, training_dataset = create_word_dataloader(\n",
        "    path = '/content/twitter_training.csv',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "testing_dataloader, testing_dataset = create_word_dataloader(\n",
        "    path = '/content/twitter_validation.csv',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "amDwcaKS_ZwB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "H59al95hMrKO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(num_epochs, model, train_dataloader, criterion):\n",
        "  total_steps = len(train_dataloader)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch, (inputs, labels) in enumerate(train_dataloader):\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (batch+1)%100==0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Step {batch+1}/{total_steps}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "1AZH_u8RNGWI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(num_epochs, model, training_dataloader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEu4K8QQPQzA",
        "outputId": "6b557d0c-df14-4471-bf0f-bebb75e5de84"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Step 100/2313, Loss: 1.3508\n",
            "Epoch 1/10, Step 200/2313, Loss: 0.8860\n",
            "Epoch 1/10, Step 300/2313, Loss: 1.3792\n",
            "Epoch 1/10, Step 400/2313, Loss: 1.3132\n",
            "Epoch 1/10, Step 500/2313, Loss: 1.5206\n",
            "Epoch 1/10, Step 600/2313, Loss: 1.0419\n",
            "Epoch 1/10, Step 700/2313, Loss: 1.3524\n",
            "Epoch 1/10, Step 800/2313, Loss: 1.5280\n",
            "Epoch 1/10, Step 900/2313, Loss: 1.5878\n",
            "Epoch 1/10, Step 1000/2313, Loss: 1.4360\n",
            "Epoch 1/10, Step 1100/2313, Loss: 1.1971\n",
            "Epoch 1/10, Step 1200/2313, Loss: 1.1113\n",
            "Epoch 1/10, Step 1300/2313, Loss: 1.5290\n",
            "Epoch 1/10, Step 1400/2313, Loss: 1.3612\n",
            "Epoch 1/10, Step 1500/2313, Loss: 1.0741\n",
            "Epoch 1/10, Step 1600/2313, Loss: 1.3307\n",
            "Epoch 1/10, Step 1700/2313, Loss: 1.1780\n",
            "Epoch 1/10, Step 1800/2313, Loss: 0.8610\n",
            "Epoch 1/10, Step 1900/2313, Loss: 1.4422\n",
            "Epoch 1/10, Step 2000/2313, Loss: 1.1028\n",
            "Epoch 1/10, Step 2100/2313, Loss: 1.4406\n",
            "Epoch 1/10, Step 2200/2313, Loss: 1.2066\n",
            "Epoch 1/10, Step 2300/2313, Loss: 1.0870\n",
            "Epoch 2/10, Step 100/2313, Loss: 1.5158\n",
            "Epoch 2/10, Step 200/2313, Loss: 0.6432\n",
            "Epoch 2/10, Step 300/2313, Loss: 1.1890\n",
            "Epoch 2/10, Step 400/2313, Loss: 0.8398\n",
            "Epoch 2/10, Step 500/2313, Loss: 1.7738\n",
            "Epoch 2/10, Step 600/2313, Loss: 1.0221\n",
            "Epoch 2/10, Step 700/2313, Loss: 1.1931\n",
            "Epoch 2/10, Step 800/2313, Loss: 1.3543\n",
            "Epoch 2/10, Step 900/2313, Loss: 1.6993\n",
            "Epoch 2/10, Step 1000/2313, Loss: 1.1951\n",
            "Epoch 2/10, Step 1100/2313, Loss: 0.7413\n",
            "Epoch 2/10, Step 1200/2313, Loss: 0.7943\n",
            "Epoch 2/10, Step 1300/2313, Loss: 1.1682\n",
            "Epoch 2/10, Step 1400/2313, Loss: 1.3090\n",
            "Epoch 2/10, Step 1500/2313, Loss: 1.7869\n",
            "Epoch 2/10, Step 1600/2313, Loss: 0.8709\n",
            "Epoch 2/10, Step 1700/2313, Loss: 1.0600\n",
            "Epoch 2/10, Step 1800/2313, Loss: 0.6992\n",
            "Epoch 2/10, Step 1900/2313, Loss: 1.1365\n",
            "Epoch 2/10, Step 2000/2313, Loss: 0.4755\n",
            "Epoch 2/10, Step 2100/2313, Loss: 1.3182\n",
            "Epoch 2/10, Step 2200/2313, Loss: 1.1858\n",
            "Epoch 2/10, Step 2300/2313, Loss: 0.8764\n",
            "Epoch 3/10, Step 100/2313, Loss: 1.4259\n",
            "Epoch 3/10, Step 200/2313, Loss: 0.4088\n",
            "Epoch 3/10, Step 300/2313, Loss: 1.0531\n",
            "Epoch 3/10, Step 400/2313, Loss: 0.5662\n",
            "Epoch 3/10, Step 500/2313, Loss: 1.6617\n",
            "Epoch 3/10, Step 600/2313, Loss: 0.6367\n",
            "Epoch 3/10, Step 700/2313, Loss: 1.0150\n",
            "Epoch 3/10, Step 800/2313, Loss: 1.4086\n",
            "Epoch 3/10, Step 900/2313, Loss: 1.9143\n",
            "Epoch 3/10, Step 1000/2313, Loss: 0.9896\n",
            "Epoch 3/10, Step 1100/2313, Loss: 0.4814\n",
            "Epoch 3/10, Step 1200/2313, Loss: 0.4038\n",
            "Epoch 3/10, Step 1300/2313, Loss: 0.8041\n",
            "Epoch 3/10, Step 1400/2313, Loss: 1.2259\n",
            "Epoch 3/10, Step 1500/2313, Loss: 1.4276\n",
            "Epoch 3/10, Step 1600/2313, Loss: 0.5857\n",
            "Epoch 3/10, Step 1700/2313, Loss: 1.0944\n",
            "Epoch 3/10, Step 1800/2313, Loss: 0.5149\n",
            "Epoch 3/10, Step 1900/2313, Loss: 0.9294\n",
            "Epoch 3/10, Step 2000/2313, Loss: 0.4846\n",
            "Epoch 3/10, Step 2100/2313, Loss: 1.0175\n",
            "Epoch 3/10, Step 2200/2313, Loss: 1.1162\n",
            "Epoch 3/10, Step 2300/2313, Loss: 0.7821\n",
            "Epoch 4/10, Step 100/2313, Loss: 1.3630\n",
            "Epoch 4/10, Step 200/2313, Loss: 0.2410\n",
            "Epoch 4/10, Step 300/2313, Loss: 0.9778\n",
            "Epoch 4/10, Step 400/2313, Loss: 0.4854\n",
            "Epoch 4/10, Step 500/2313, Loss: 1.1513\n",
            "Epoch 4/10, Step 600/2313, Loss: 0.3538\n",
            "Epoch 4/10, Step 700/2313, Loss: 0.8949\n",
            "Epoch 4/10, Step 800/2313, Loss: 1.0669\n",
            "Epoch 4/10, Step 900/2313, Loss: 1.5919\n",
            "Epoch 4/10, Step 1000/2313, Loss: 0.7991\n",
            "Epoch 4/10, Step 1100/2313, Loss: 0.2843\n",
            "Epoch 4/10, Step 1200/2313, Loss: 0.2863\n",
            "Epoch 4/10, Step 1300/2313, Loss: 0.5127\n",
            "Epoch 4/10, Step 1400/2313, Loss: 1.1811\n",
            "Epoch 4/10, Step 1500/2313, Loss: 0.7106\n",
            "Epoch 4/10, Step 1600/2313, Loss: 0.4625\n",
            "Epoch 4/10, Step 1700/2313, Loss: 1.0074\n",
            "Epoch 4/10, Step 1800/2313, Loss: 0.4015\n",
            "Epoch 4/10, Step 1900/2313, Loss: 0.5210\n",
            "Epoch 4/10, Step 2000/2313, Loss: 0.3528\n",
            "Epoch 4/10, Step 2100/2313, Loss: 0.8304\n",
            "Epoch 4/10, Step 2200/2313, Loss: 0.9358\n",
            "Epoch 4/10, Step 2300/2313, Loss: 0.5470\n",
            "Epoch 5/10, Step 100/2313, Loss: 1.4093\n",
            "Epoch 5/10, Step 200/2313, Loss: 0.1002\n",
            "Epoch 5/10, Step 300/2313, Loss: 0.9998\n",
            "Epoch 5/10, Step 400/2313, Loss: 0.3974\n",
            "Epoch 5/10, Step 500/2313, Loss: 0.5374\n",
            "Epoch 5/10, Step 600/2313, Loss: 0.2387\n",
            "Epoch 5/10, Step 700/2313, Loss: 0.6054\n",
            "Epoch 5/10, Step 800/2313, Loss: 1.0364\n",
            "Epoch 5/10, Step 900/2313, Loss: 1.0864\n",
            "Epoch 5/10, Step 1000/2313, Loss: 0.2838\n",
            "Epoch 5/10, Step 1100/2313, Loss: 0.2458\n",
            "Epoch 5/10, Step 1200/2313, Loss: 0.0653\n",
            "Epoch 5/10, Step 1300/2313, Loss: 0.3824\n",
            "Epoch 5/10, Step 1400/2313, Loss: 1.2810\n",
            "Epoch 5/10, Step 1500/2313, Loss: 0.5420\n",
            "Epoch 5/10, Step 1600/2313, Loss: 0.2752\n",
            "Epoch 5/10, Step 1700/2313, Loss: 0.9888\n",
            "Epoch 5/10, Step 1800/2313, Loss: 0.2289\n",
            "Epoch 5/10, Step 1900/2313, Loss: 0.2452\n",
            "Epoch 5/10, Step 2000/2313, Loss: 0.3312\n",
            "Epoch 5/10, Step 2100/2313, Loss: 0.2865\n",
            "Epoch 5/10, Step 2200/2313, Loss: 0.7808\n",
            "Epoch 5/10, Step 2300/2313, Loss: 0.3099\n",
            "Epoch 6/10, Step 100/2313, Loss: 0.8840\n",
            "Epoch 6/10, Step 200/2313, Loss: 0.1352\n",
            "Epoch 6/10, Step 300/2313, Loss: 0.6586\n",
            "Epoch 6/10, Step 400/2313, Loss: 0.2485\n",
            "Epoch 6/10, Step 500/2313, Loss: 0.3877\n",
            "Epoch 6/10, Step 600/2313, Loss: 0.2013\n",
            "Epoch 6/10, Step 700/2313, Loss: 0.4511\n",
            "Epoch 6/10, Step 800/2313, Loss: 0.7160\n",
            "Epoch 6/10, Step 900/2313, Loss: 0.7034\n",
            "Epoch 6/10, Step 1000/2313, Loss: 0.1164\n",
            "Epoch 6/10, Step 1100/2313, Loss: 0.1306\n",
            "Epoch 6/10, Step 1200/2313, Loss: 0.0322\n",
            "Epoch 6/10, Step 1300/2313, Loss: 0.1403\n",
            "Epoch 6/10, Step 1400/2313, Loss: 1.0599\n",
            "Epoch 6/10, Step 1500/2313, Loss: 0.3955\n",
            "Epoch 6/10, Step 1600/2313, Loss: 0.3010\n",
            "Epoch 6/10, Step 1700/2313, Loss: 0.8417\n",
            "Epoch 6/10, Step 1800/2313, Loss: 0.2105\n",
            "Epoch 6/10, Step 1900/2313, Loss: 0.1098\n",
            "Epoch 6/10, Step 2000/2313, Loss: 0.2694\n",
            "Epoch 6/10, Step 2100/2313, Loss: 0.0987\n",
            "Epoch 6/10, Step 2200/2313, Loss: 0.5204\n",
            "Epoch 6/10, Step 2300/2313, Loss: 0.2608\n",
            "Epoch 7/10, Step 100/2313, Loss: 1.1219\n",
            "Epoch 7/10, Step 200/2313, Loss: 0.1041\n",
            "Epoch 7/10, Step 300/2313, Loss: 0.5936\n",
            "Epoch 7/10, Step 400/2313, Loss: 0.1656\n",
            "Epoch 7/10, Step 500/2313, Loss: 0.1685\n",
            "Epoch 7/10, Step 600/2313, Loss: 0.1442\n",
            "Epoch 7/10, Step 700/2313, Loss: 0.4062\n",
            "Epoch 7/10, Step 800/2313, Loss: 0.5225\n",
            "Epoch 7/10, Step 900/2313, Loss: 0.4973\n",
            "Epoch 7/10, Step 1000/2313, Loss: 0.0383\n",
            "Epoch 7/10, Step 1100/2313, Loss: 0.1285\n",
            "Epoch 7/10, Step 1200/2313, Loss: 0.0069\n",
            "Epoch 7/10, Step 1300/2313, Loss: 0.0726\n",
            "Epoch 7/10, Step 1400/2313, Loss: 0.5813\n",
            "Epoch 7/10, Step 1500/2313, Loss: 0.3402\n",
            "Epoch 7/10, Step 1600/2313, Loss: 0.3384\n",
            "Epoch 7/10, Step 1700/2313, Loss: 0.9255\n",
            "Epoch 7/10, Step 1800/2313, Loss: 0.3151\n",
            "Epoch 7/10, Step 1900/2313, Loss: 0.2142\n",
            "Epoch 7/10, Step 2000/2313, Loss: 0.2102\n",
            "Epoch 7/10, Step 2100/2313, Loss: 0.0519\n",
            "Epoch 7/10, Step 2200/2313, Loss: 0.3690\n",
            "Epoch 7/10, Step 2300/2313, Loss: 0.1891\n",
            "Epoch 8/10, Step 100/2313, Loss: 0.4814\n",
            "Epoch 8/10, Step 200/2313, Loss: 0.0285\n",
            "Epoch 8/10, Step 300/2313, Loss: 0.4009\n",
            "Epoch 8/10, Step 400/2313, Loss: 0.1907\n",
            "Epoch 8/10, Step 500/2313, Loss: 0.1279\n",
            "Epoch 8/10, Step 600/2313, Loss: 0.1872\n",
            "Epoch 8/10, Step 700/2313, Loss: 0.2999\n",
            "Epoch 8/10, Step 800/2313, Loss: 0.5276\n",
            "Epoch 8/10, Step 900/2313, Loss: 0.3827\n",
            "Epoch 8/10, Step 1000/2313, Loss: 0.0529\n",
            "Epoch 8/10, Step 1100/2313, Loss: 0.0174\n",
            "Epoch 8/10, Step 1200/2313, Loss: 0.0077\n",
            "Epoch 8/10, Step 1300/2313, Loss: 0.0863\n",
            "Epoch 8/10, Step 1400/2313, Loss: 0.2622\n",
            "Epoch 8/10, Step 1500/2313, Loss: 0.3742\n",
            "Epoch 8/10, Step 1600/2313, Loss: 0.1379\n",
            "Epoch 8/10, Step 1700/2313, Loss: 0.6639\n",
            "Epoch 8/10, Step 1800/2313, Loss: 0.1494\n",
            "Epoch 8/10, Step 1900/2313, Loss: 0.0461\n",
            "Epoch 8/10, Step 2000/2313, Loss: 0.2446\n",
            "Epoch 8/10, Step 2100/2313, Loss: 0.0443\n",
            "Epoch 8/10, Step 2200/2313, Loss: 0.1855\n",
            "Epoch 8/10, Step 2300/2313, Loss: 0.1687\n",
            "Epoch 9/10, Step 100/2313, Loss: 0.4418\n",
            "Epoch 9/10, Step 200/2313, Loss: 0.0084\n",
            "Epoch 9/10, Step 300/2313, Loss: 0.9018\n",
            "Epoch 9/10, Step 400/2313, Loss: 0.0800\n",
            "Epoch 9/10, Step 500/2313, Loss: 0.1037\n",
            "Epoch 9/10, Step 600/2313, Loss: 0.1328\n",
            "Epoch 9/10, Step 700/2313, Loss: 0.2938\n",
            "Epoch 9/10, Step 800/2313, Loss: 0.5956\n",
            "Epoch 9/10, Step 900/2313, Loss: 0.2397\n",
            "Epoch 9/10, Step 1000/2313, Loss: 0.0960\n",
            "Epoch 9/10, Step 1100/2313, Loss: 0.0692\n",
            "Epoch 9/10, Step 1200/2313, Loss: 0.0024\n",
            "Epoch 9/10, Step 1300/2313, Loss: 0.0133\n",
            "Epoch 9/10, Step 1400/2313, Loss: 0.4969\n",
            "Epoch 9/10, Step 1500/2313, Loss: 0.3424\n",
            "Epoch 9/10, Step 1600/2313, Loss: 0.1784\n",
            "Epoch 9/10, Step 1700/2313, Loss: 0.5253\n",
            "Epoch 9/10, Step 1800/2313, Loss: 0.1574\n",
            "Epoch 9/10, Step 1900/2313, Loss: 0.0479\n",
            "Epoch 9/10, Step 2000/2313, Loss: 0.1586\n",
            "Epoch 9/10, Step 2100/2313, Loss: 0.1131\n",
            "Epoch 9/10, Step 2200/2313, Loss: 0.1017\n",
            "Epoch 9/10, Step 2300/2313, Loss: 0.8617\n",
            "Epoch 10/10, Step 100/2313, Loss: 0.3193\n",
            "Epoch 10/10, Step 200/2313, Loss: 0.1172\n",
            "Epoch 10/10, Step 300/2313, Loss: 0.2379\n",
            "Epoch 10/10, Step 400/2313, Loss: 0.0648\n",
            "Epoch 10/10, Step 500/2313, Loss: 0.0872\n",
            "Epoch 10/10, Step 600/2313, Loss: 0.1301\n",
            "Epoch 10/10, Step 700/2313, Loss: 0.3571\n",
            "Epoch 10/10, Step 800/2313, Loss: 0.5403\n",
            "Epoch 10/10, Step 900/2313, Loss: 0.1523\n",
            "Epoch 10/10, Step 1000/2313, Loss: 0.0247\n",
            "Epoch 10/10, Step 1100/2313, Loss: 0.0224\n",
            "Epoch 10/10, Step 1200/2313, Loss: 0.0097\n",
            "Epoch 10/10, Step 1300/2313, Loss: 0.0577\n",
            "Epoch 10/10, Step 1400/2313, Loss: 0.1369\n",
            "Epoch 10/10, Step 1500/2313, Loss: 0.1220\n",
            "Epoch 10/10, Step 1600/2313, Loss: 0.0971\n",
            "Epoch 10/10, Step 1700/2313, Loss: 0.4469\n",
            "Epoch 10/10, Step 1800/2313, Loss: 0.2118\n",
            "Epoch 10/10, Step 1900/2313, Loss: 0.1681\n",
            "Epoch 10/10, Step 2000/2313, Loss: 0.1868\n",
            "Epoch 10/10, Step 2100/2313, Loss: 0.0351\n",
            "Epoch 10/10, Step 2200/2313, Loss: 0.2002\n",
            "Epoch 10/10, Step 2300/2313, Loss: 0.1486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()  # set to eval mode (important: disables dropout, etc.)\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            outputs = model(inputs)             # [batch_size, num_classes]\n",
        "            loss = criterion(outputs, labels)   # compute loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "JLKhSHSQ5geI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, testing_dataloader,criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i8fOkAQ5lsR",
        "outputId": "1dbb26d7-7a81-4734-b0bb-321199aa30cf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4225795868005662, 0.9)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save only the model weights (state_dict)\n",
        "torch.save(model.state_dict(), \"sentiment_lstm_weights.pt\")\n",
        "print(\"✅ Model weights saved as sentiment_lstm_weights.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn7_IfDjw2-h",
        "outputId": "53e11f5b-18f3-48d5-c205-ab3df795d54a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model weights saved as sentiment_lstm_weights.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the full model (architecture + weights)\n",
        "torch.save(model, \"sentiment_lstm_full.pt\")\n",
        "print(\"✅ Full model saved as sentiment_lstm_full.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_Hf1iHnxBu_",
        "outputId": "dea44903-dd0b-443d-c8a9-c5bbe4d59e87"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Full model saved as sentiment_lstm_full.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Option A: Load only weights ---\n",
        "model = SentimentLSTM(vocab_size, hidden_dim, embedding_dim)\n",
        "model.load_state_dict(torch.load(\"sentiment_lstm_weights.pt\"))\n",
        "model.eval()\n",
        "print(\"✅ Model reloaded from weights\")\n",
        "\n",
        "# --- Option B: Load full model ---\n",
        "# model = torch.load(\"sentiment_lstm_full.pt\")\n",
        "# model.eval()\n",
        "# print(\"✅ Full model reloaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q9iogIpxN8j",
        "outputId": "d79f9b9d-6e66-462a-a7d7-cedc50e90ba7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model reloaded from weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, text, tokenizer, max_length=50, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Predict sentiment for a single phrase.\n",
        "    Args:\n",
        "        model: trained LSTM model\n",
        "        text (str): phrase to analyze\n",
        "        tokenizer: your tokenizer (e.g. tiktoken or custom)\n",
        "        max_length (int): max sequence length\n",
        "        device (str): \"cpu\" or \"cuda\"\n",
        "    Returns:\n",
        "        int: predicted class index\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    text = clean_text(text)\n",
        "    # Tokenize and convert to IDs\n",
        "    token_ids = tokenizer.encode(text)\n",
        "\n",
        "    # Pad or truncate\n",
        "    if len(token_ids) < max_length:\n",
        "        token_ids += [0] * (max_length - len(token_ids))\n",
        "    else:\n",
        "        token_ids = token_ids[:max_length]\n",
        "\n",
        "    # Convert to tensor with batch size 1\n",
        "    input_tensor = torch.tensor([token_ids], dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    return pred_class\n"
      ],
      "metadata": {
        "id": "HZHHI5uCxiWF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I really love this game! 😍\"\n",
        "response = predict_sentiment(model, text, tokenizer)\n",
        "print(f\"Message: {text} | Sentiment: {dataset.encoder.classes_[response]}\")\n",
        "text =  \"This was the worst experience ever 😡\"\n",
        "response = predict_sentiment(model, text, tokenizer)\n",
        "print(f\"Message: {text} | Sentiment: {dataset.encoder.classes_[response]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0J2KamzxlDU",
        "outputId": "e6fb0110-aa5f-4373-d9d8-c71df8323602"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: I really love this game! 😍 | Sentiment: Positive\n",
            "Message: This was the worst experience ever 😡 | Sentiment: Negative\n"
          ]
        }
      ]
    }
  ]
}